  1: regression data set memory usage test
  2: check manually extracted ngrams
  3: (obsolete) single label feature extraction using elasticsearch,
  4: single label feature sampling gradient boosting
  5: build cnn index
  6: check purity of features
  7: dump data set info for exp3
  8: index Ohsumed_20000
  9: merge 20nesgroup into 8 classes
  10: ecoc
  11: (obsolete)for single label dataset, dump unigram features (documented config)
  12: for multi label dataset, dump ngram features
  13: hmlgb
  14: imlgb
  15: feature extraction for multi label dataset
  16: index review polarity
  17: index classic3
  18: (obsolete) single label dataset, start with initial features + all unigram features
       use picked unigram features as seeds
  19: single label gradient boosting without probabilistic voting
  20: (obsolete) single label lasso (obsolete)
  21: (obsolete) single label ridge
  22: (obsolete) elastic net hyper parameter tuning, single label
  23: index 20newsgroup
  24: index imdb(deprecated)
  25: (obsolete) elastic net, single label
  26: gradient boosting hyper parameter tuning, single label
  27: (obsolete) lasso hyper parameter tuning
  28: (obsolete) ridge hyper parameter tuning
  29: index imdb
  30: given logistic regression coefficients, print top features
  31: feature extraction by logistic regression, see 37
  32: (obsolete) given feature indices, get feature names
  33: logistic regression
  34: logistic regression hyper parameter tuning via cross validation
  35: dump ngram features
      split to train/valid/test
  36: logistic regression hyper parameter tuning with validation set
  37: (obsolete) feature extraction by logistic regression, with train/valid/test split
       start with all unigrams
       only extract ngrams
  38: index sentence polarity
  39: index subjectivity
  40: index amazon review
  41: multi-label logistic regression
  42: multi-label logistic regression hyper parameter tuning via cross-validation
  43: index question classification
  44: index blog gender
  45: index wipo
  46: index trec spam
  47: (obsolete) feature extraction by logistic regression, with train/valid/test split
      start with specified features
      extract both unigrams and ngrams
  48: (obsolete) feature extraction by boosting, with train/valid/test split
      start with specified features
      extract both unigrams and ngrams
  49: (obsolete) feature extraction by logistic regression, with train/valid/test split
      start with specified features
      extract both unigrams and ngrams
      use focus set with promotion
  50: (obsolete) exp49 + exp 36 + exp33
  51: (obsolete) feature extraction by boosting, with train/valid/test split
       start with specified features
       extract both unigrams and ngrams
       use focus set with promotion
  52: index imdb_movie_genre
  53: index amazon_book_genre
  54: check number of ngrams
  55: (obsolete)feature extraction by logistic regression,
      start with specified features
      extract both unigrams and ngrams
      dynamic seeds
  56: detect duplicated docs in an index
  57: (obsolete)check the difference between two datasets
  58: feature extraction by boosting, dynamic seeds
  59: (obsolete) check whether important features in one dataset appear in another dataset
  60: obsolete
  61: dump most common unigrams
  62: (obsolete)extract all frequent ngrams from a document, check how probability estimation changes
  63: check distribution of good ngrams
  64: write data to the seql format
  65: index imdb as multi-label
  66: set cover good ngrams
  67: (obsolete) deal with negations in a dataset
  68: test ridge logistic regression with noisy features
  69: check white house vs white/house
  70: elastic-net logistic regression
  71: (obsolete)test lbfgs on synthetic functions
  72: adaboost.MH
  73: logistic gradient feature selection
  74: regression stump feature selection
  75: approximate logistic gradients
  76: elasticsearch benchmark
  77: test fused kolmogorov filter on a complete matrix
  78: visualize Kolmogorovâ€“Smirnov test
  79: logistic regression analysis, can take any logistic regression(ridge, lasso, elasticnet)
  80: get frequent nouns
  81: step-wise logistic regression on a given matrix
  83: dump features for one trec 8 query
  84: dump features for all queries in trec 8
  85: run logistic regression on all trec8 queries
  86: build trec8 index
  87: index congressional bill dataset
  88: spanNot query based on bigrams
  89: index recon
  90: elasticnet logistic regression, fix regularization first
  91: select a subset of features based on feature types
  92: partition train into train/valid
  93: same as exp70, for tunning
  94: keep features with mindf
  95: index yelp
  96: concatenate datasets by features
  97: merge train and test, repartition into folds
  98: loop on Exp97
  99: elastic for 5folds
  100: check dataset information
  103: index amazon_phone, class demo
  104: multi-label logistic regression, trained independently
  105: soft regression stump, fit univariate function
  106: soft tree, convergence test
  107: hard regression stump vs soft regresson stump on real datasets, use the same split feature
  108: tree noise test, noise =0.1
  109: tree, fitting sparse data
  110: tree, fitting sparse and noisy data
  111: fitting multi-variate function with regression stumps
  112: visualize residuals for lktb with hard trees
  113: visualize residuals for lktb with expectation trees
  114: visualize residuals for lktb with probabilistic trees
  115: hard tree vs expectation tree vs hybrid tree, accuracy test, spam data
  116: hard tree vs expectation tree vs hybrid tree, accuracy test, on fiji, no newton, no shrinkage
  117: hard tree vs expectation tree vs hybrid tree, accuracy test, on fiji, with shrinkage, without newton, used convergence check to stop early
  118:  classification, hard tree vs expectation tree vs hybrid tree, accuracy test, on fiji, with shrinkage, without newton, always run lbfgs for 100 iterations
  119:  regression, LS BOOST, soft tree vs hard tree vs hybrid tree, fiji
  120: LS BOOST, soft tree vs hard tree vs hybrid tree, simulation data, local, no shrinkage
  121: LS BOOST, soft tree vs hard tree vs hybrid tree, simulation data, local, shrinkage=0.1
  122: follow exp119, check why soft tree performs worse on certain iterations
