############## input and output ###############

# Full path to input train dataset
input.trainData=/scratch/li.che/mlc_data_pyramid/rcv1subset_topics_1/train_test_split/train

# Full path to input validation dataset, if available
# Used for hyper parameter tuning and early stopping
# If no additional validation set is available, leave it as blank, 
# and random 20% of the training data will be used as the validation set. 
input.validData=

# Full path to input test dataset
input.testData=/scratch/li.che/mlc_data_pyramid/rcv1subset_topics_1/train_test_split/test

# Directory for the program output
output.dir=/scratch/li.che/out/cbm_en/rcv1/1

# Whether to show detailed debugging information
output.verbose=false

################# functions #####################

# Perform hyper parameter tuning before training
# If external validation data is given, the model is trained on the full training data
# and tuned on the given validation data; otherwise, the model is trained on 80% of the training data,
# and tuned on the rest 20% of the training data.
tune=true

# Train the model on all the available data (excluding test data), using tuned or user specified hyper parameters
# If the external validation data is also given, the model is trained on training data + validation data
train=true

# Load back trained model, make predictions on the test set, and evaluate test performance.
# The program shows several different predictions designed to optimize different evaluation metrics.
test=true

######### prediction method ########

# Whether to allow empty subset to be predicted; 
# true = allow empty prediction
# false = do not allow empty prediction
# auto = allow empty prediction only if the training set contains empty label sets
predict.allowEmpty=auto

# The threshold for skipping components with small contributions
# This is designed to speed up prediction
predict.piThreshold=0.001


######### tune #########
# Hyper parameter tuning uses the validation set to decide elasticnet penalty and L1 ratio, 
# number of CBM components and number of EM training iterations.
# Users can specify candidate values for penalty, L1 ratio and components.
# The optimal EM training iterations will be determined automatically by monitoring the validation performance.
# The metric monitored is specified in predict.targetMetric.

# To achieve optimal prediction under which target evaluation metric? 
# Currently supported metrics: instance_set_accuracy, instance_f1 and instance_hamming_loss.
# Generally speaking no single model is well suited for all evaluation metrics.
# Optimizing different metrics require different prediction methods and hyper parameters.
# The program automatically chooses the optimal prediction method designed for each metric.
# The predictor designed for instance set accuracy outputs the joint mode.
# The predictor designed for instance Hamming loss outputs the marginal modes.
# The predictor designed for instance F1 runs the GFM algorithm.
# The metric specified here will serve as the main metric for selecting the best model during hyper parameter tuning
# Once the model is trained, the program shows all different predictions made by different prediction methods
tune.targetMetric=instance_f1

# the overall elastic-net penalty is a weighted combination of L1 norm and L2 norm and has the form 
# penalty*[l1Ratio*L1 norm + (1-l1Ratio)L2 norm]

# What values to try for the overall elastic-net penalty 
# Big values indicate strong regularizations
# The penalty can greatly affect the performance and thus requires careful tuning
tune.penalty.candidates=0.0001,0.000001

# What values to try for L1 Ratio
# Any real number from 0 to 1, where 0 means L2 only, 1 means L1 only, and 0.5 means half L1 and half L2.
tune.l1Ratio.candidates=0.1,0.5

# What values to try for number of CBM components
# The default value 50 usually gives good performance
# To reduce turning time, users can just set tune.numComponents.candidates=50
tune.numComponents.candidates=50


# Evaluate the metric on the validation set every k iterations
# Frequent evaluation may slow down training
# Use a small value (e.g. 1) if we expect the training to take just a few iterations (e.g. 20)
# Use a big value (e.g. 10) if we expect the training to take many iterations (e.g. 200)
tune.monitorInterval=1

# the model training will never stop before it reaches this minimum number of iterations
tune.earlyStop.minIterations=5

# If the validation metric does not improve after k successive evaluations, the training will stop
# for example, if tune.monitorInterval=5 and tune.earlyStop.patience=2, trains stops if no improvement in 10 iterations
# Using a patient value too small make cause the training to stop too early
# Using a patient value too big make increase the tuning time
tune.earlyStop.patience=10


######### train #################
# Whether to use optimal hyper parameter value found by tuning
# These hyper parameters include: train.iterations, train.penalty, train.l1Ratio, elasticnet.lineSearch,
# elasticnet.activeSet, random.initial and train.numComponents

# if true, users do not need to specify these values
# if false or if no tuning has be performed, users need to provide a value for each of them 
train.useTunedHyperParameters=true

# Number of EM training iterations
train.iterations=10

# the overall elastic-net penalty is a weighted combination of L1 norm and L2 norm and has the form 
# penalty*[l1Ratio*L1 norm + (1-l1Ratio)L2 norm]

# Big values indicate strong regularizations
# The penalty can greatly affect the performance and thus requires careful tuning
train.penalty=0.0001

# Any real number from 0 to 1, where 0 means L2 only, 1 means L1 only, and 0.5 means half L1 and half L2.
train.l1Ratio=1.0

# whether to use line search for elastic-net training
# default=false
# in very rare occasions, the training may diverge without line search; if this happens, set lineSearch=true
elasticnet.lineSearch=false

# whether to initialize CBM by random parameters
# default is false and uses BM to initialize CBM
random.initial=false


# whether to speed up elastic-net training using the active set trick
elasticnet.activeSet=true

# Number of CBM components
# The default value 50 usually gives good performance
train.numComponents=20


# The parameters below usually do not affect the performance much
# Users can use default values

# number of Coordinate Descent algorithm iterations for LR in each M step
# The default value 5 is good most of the time
# If the train.iterations found by hyper parameter tuning is 1 or 2, each M step is probably doing too much work and the training overfits too quickly. In this case, we can decrease train.updatesPerIteration
binary.updatesPerIteration=5
multiClass.updatesPerIteration=5

# In each component, skip instances with small memberships values (gammas)
# This is designed to speed up training
train.skipDataThreshold=0.00001
skipDataThreshold=0.00001

# Skip training a classifier for a label in a component if that label almost never appears or almost always appears in that component. 
# A constant output (the prior probability) will be used in this case.
# This is designed to speed up training
train.skipLabelThreshold=0.00001
skipLabelThreshold=0.00001
# Smooth the probability of a non-existent label in a component with the its overall probability in the dataset
# This is designed to avoid zero probabilities
train.smoothStrength=0.0001

######## test ##############
# When generating prediction reports for individual label probabilities, labels with probabilities below the threshold will not be displayed
# This only make the reports more readable; it does not affect the actual prediction in any way.
report.labelProbThreshold=0.2





# the internal Java class name for this application. 
# users do not need to modify this.
pyramid.class=CBMEN

